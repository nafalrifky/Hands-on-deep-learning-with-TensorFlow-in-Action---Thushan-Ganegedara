{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 — Dipping Toes in Deep Learning\n",
    "This chapter provides a practical introduction to three fundamental types of deep neural networks: Fully Connected Networks (FCNs), Convolutional Neural Networks (CNNs), and Recurrent Neural Networks (RNNs). Each section includes implementation examples and real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Fully Connected Networks (FCNs)\n",
    "FCNs, also known as Multilayer Perceptrons (MLPs), form the foundation of deep learning. In this chapter, we explore autoencoders - a type of FCN used for unsupervised learning tasks like image reconstruction and denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Autoencoder Architecture\n",
    "Autoencoders learn to compress input data into a latent representation and then reconstruct it. They consist of:\n",
    "- **Encoder**: Compresses input to latent space\n",
    "- **Decoder**: Reconstructs input from latent space\n",
    "- **Applications**: Denoising, dimensionality reduction, pretraining\n",
    "\n",
    "**Key Concept**: The autoencoder takes corrupted images as input and learns to reconstruct the original images through compression and reconstruction phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Denoising Autoencoder\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "autoencoder = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(784, activation='tanh')\n",
    "])\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Training Process\n",
    "- **Input**: Corrupted images (50% pixels randomly set to 0)\n",
    "- **Target**: Original clean images\n",
    "- **Loss**: Mean Squared Error (MSE)\n",
    "- **Result**: Model learns to reconstruct original digits from corrupted versions\n",
    "- **Dataset**: MNIST - 70,000 handwritten digit images (28×28 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for MNIST\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "def generate_masked_inputs(x, p, seed=None):\n",
    "    \"\"\"Generate corrupted images by randomly setting pixels to 0\"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    mask = np.random.binomial(n=1, p=p, size=x.shape).astype('float32')\n",
    "    return x * mask\n",
    "\n",
    "# Normalize and reshape MNIST data\n",
    "norm_x_train = ((x_train - 128.0)/128.0).reshape([-1,784])\n",
    "masked_x_train = generate_masked_inputs(norm_x_train, 0.5)\n",
    "\n",
    "print(f\"Original data shape: {x_train.shape}\")\n",
    "print(f\"Normalized data shape: {norm_x_train.shape}\")\n",
    "print(f\"Masked data shape: {masked_x_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Results and Applications\n",
    "- **Performance**: Loss decreases from ~0.15 to ~0.078 over 10 epochs\n",
    "- **Visual Results**: Model successfully reconstructs corrupted digit images\n",
    "- **Real-world Use**: Photo restoration, feature learning, pretraining for supervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(masked_x_train, norm_x_train, \n",
    "                        batch_size=64, epochs=10, verbose=1)\n",
    "\n",
    "# Test reconstruction\n",
    "test_sample = x_train[:5]\n",
    "norm_test = ((test_sample - 128.0)/128.0).reshape([-1,784])\n",
    "masked_test = generate_masked_inputs(norm_test, 0.5, seed=2048)\n",
    "reconstructed = autoencoder.predict(masked_test)\n",
    "\n",
    "print(\"Reconstruction completed!\")\n",
    "print(f\"Input shape: {masked_test.shape}\")\n",
    "print(f\"Output shape: {reconstructed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Convolutional Neural Networks (CNNs)\n",
    "CNNs revolutionized computer vision by preserving spatial information and learning hierarchical features through convolution and pooling operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 CNN Architecture Components\n",
    "- **Convolution Layers**: Extract spatial features using learnable filters\n",
    "- **Pooling Layers**: Reduce spatial dimensions (MaxPooling, AveragePooling)\n",
    "- **Fully Connected Layers**: Final classification layers\n",
    "- **Key Advantage**: Parameter efficiency through weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Implementation for CIFAR-10\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    # First Conv-Pool Block\n",
    "    layers.Conv2D(16, (3,3), strides=(2,2), activation='relu', \n",
    "                  padding='same', input_shape=(32,32,3)),\n",
    "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "    \n",
    "    # Second Conv-Pool Block\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same'),\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Convolution Operation Details\n",
    "Key hyperparameters that affect convolution output:\n",
    "\n",
    "**Filters**: Number of output channels  \n",
    "**Kernel Size**: Spatial dimensions of convolution window  \n",
    "**Strides**: Step size for sliding the kernel  \n",
    "**Padding**: 'same' (output size = input size) or 'valid' (no padding)\n",
    "\n",
    "**Output Size Formula**:  \n",
    "For valid padding: `output_size = (input_size - kernel_size) / stride + 1`  \n",
    "For same padding: `output_size = input_size / stride` (rounded up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate convolution output sizes\n",
    "def calculate_output_size(input_size, kernel_size, stride, padding):\n",
    "    \"\"\"Calculate convolution output size to avoid errors\"\"\"\n",
    "    if padding == 'valid':\n",
    "        return (input_size - kernel_size) // stride + 1\n",
    "    else:  # 'same'\n",
    "        return (input_size + stride - 1) // stride\n",
    "\n",
    "# Example: Check CNN architecture validity\n",
    "input_size = 32\n",
    "layers_config = [\n",
    "    {'type': 'conv', 'kernel': 3, 'stride': 2, 'padding': 'same'},\n",
    "    {'type': 'pool', 'kernel': 2, 'stride': 2, 'padding': 'same'},\n",
    "    {'type': 'conv', 'kernel': 3, 'stride': 1, 'padding': 'same'},\n",
    "    {'type': 'pool', 'kernel': 2, 'stride': 2, 'padding': 'same'}\n",
    "]\n",
    "\n",
    "current_size = input_size\n",
    "for i, layer in enumerate(layers_config):\n",
    "    current_size = calculate_output_size(current_size, layer['kernel'], layer['stride'], layer['padding'])\n",
    "    print(f\"After layer {i+1} ({layer['type']}): {current_size}\")\n",
    "\n",
    "print(f\"\\nFinal feature map size before flattening: {current_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 CIFAR-10 Implementation\n",
    "- **Dataset**: 50,000 training and 10,000 test images across 10 classes\n",
    "- **Image Size**: 32×32 RGB images\n",
    "- **Classes**: Airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- **Results**: ~72% training accuracy after 25 epochs\n",
    "- **Application**: Vehicle detection feasibility study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation for CIFAR-10\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "def format_data(x, depth):\n",
    "    \"\"\"Convert images to float32 and labels to one-hot\"\"\"\n",
    "    return (tf.cast(x[\"image\"], 'float32'), tf.one_hot(x[\"label\"], depth=depth))\n",
    "\n",
    "# Load and prepare dataset\n",
    "data = tfds.load('cifar10')\n",
    "tr_data = data[\"train\"].map(lambda x: format_data(x, depth=10)).batch(32)\n",
    "\n",
    "# Inspect the data\n",
    "for batch in tr_data.take(1):\n",
    "    images, labels = batch\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n",
    "    print(f\"Image range: [{tf.reduce_min(images):.2f}, {tf.reduce_max(images):.2f}]\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN model\n",
    "print(\"Training CNN on CIFAR-10...\")\n",
    "history = cnn.fit(tr_data, epochs=5, verbose=1)  # Using 5 epochs for demonstration\n",
    "\n",
    "print(\"Training completed!\")\n",
    "final_accuracy = history.history['acc'][-1]\n",
    "print(f\"Final training accuracy: {final_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Recurrent Neural Networks (RNNs)\n",
    "RNNs are designed for sequential data and time series analysis, maintaining memory of previous inputs through hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 RNN vs Feed-Forward Networks\n",
    "- **Feed-Forward**: Each input processed independently\n",
    "- **RNN**: Maintains hidden state that captures information from previous time steps\n",
    "- **Applications**: Time series forecasting, natural language processing, speech recognition\n",
    "- **Key Concept**: RNNs use previous context to inform current predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 CO2 Concentration Prediction\n",
    "Practical application: Predicting future CO2 levels using historical data\n",
    "- **Data Source**: Monthly CO2 concentration measurements since 1980\n",
    "- **Task**: Predict next month's CO2 level using previous 12 months\n",
    "- **Approach**: RNN learns temporal patterns in atmospheric CO2 data\n",
    "- **Columns**: Date, Decimal Date, Average CO2, Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for CO2 Prediction\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_co2_data():\n",
    "    \"\"\"Download CO2 concentration data\"\"\"\n",
    "    save_dir = \"data\"\n",
    "    save_path = os.path.join(save_dir, 'co2-mm-gl.csv')\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        url = \"https://datahub.io/core/co2-ppm/r/co2-mm-gl.csv\"\n",
    "        r = requests.get(url)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(\"Data downloaded successfully!\")\n",
    "    else:\n",
    "        print(\"Data already exists!\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Load and explore data\n",
    "data_path = download_co2_data()\n",
    "co2_data = pd.read_csv(data_path)\n",
    "\n",
    "print(\"CO2 Data Sample:\")\n",
    "print(co2_data.head())\n",
    "print(f\"\\nDataset shape: {co2_data.shape}\")\n",
    "print(f\"\\nColumns: {co2_data.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {co2_data['Date'].min()} to {co2_data['Date'].max()}\")\n",
    "print(f\"\\nCO2 concentration range: {co2_data['Average'].min():.2f} to {co2_data['Average'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Sequence Processing in RNNs\n",
    "RNNs process sequences by:\n",
    "- Maintaining internal state across time steps\n",
    "- Learning temporal dependencies\n",
    "- Using previous predictions to inform future ones\n",
    "- Handling variable-length sequences\n",
    "- **Mathematical Form**: h_t = f(W * x_t + U * h_{t-1} + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN implementation for CO2 prediction\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# Prepare sequential data\n",
    "def create_sequences(data, sequence_length=12):\n",
    "    \"\"\"Create sequences for RNN training\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        target = data[i + sequence_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Use CO2 average values\n",
    "co2_values = co2_data['Average'].values\n",
    "sequences, targets = create_sequences(co2_values, sequence_length=12)\n",
    "\n",
    "print(f\"Sequences shape: {sequences.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "print(f\"Sample sequence: {sequences[0]}\")\n",
    "print(f\"Corresponding target: {targets[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Network Comparisons\n",
    "\n",
    "### Table 4.1 — Network Type Applications\n",
    "| Network Type | Best For | Key Features | Example Applications |\n",
    "|-------------|----------|--------------|---------------------|\n",
    "| FCNs | Tabular data, Simple patterns | Fully connected layers, No spatial preservation | Autoencoders, Basic classification |\n",
    "| CNNs | Image data, Spatial patterns | Convolution layers, Parameter sharing, Translation invariance | Image classification, Object detection |\n",
    "| RNNs | Sequential data, Time series | Hidden states, Temporal dependencies | Forecasting, NLP, Speech recognition |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Considerations\n",
    "\n",
    "### 4.4.1 Hyperparameter Optimization\n",
    "- Deep learning models often use empirically chosen architectures\n",
    "- Hyperparameter optimization is computationally expensive\n",
    "- Common strategies: Transfer learning, following published architectures, rules of thumb\n",
    "- **Rule of Thumb**: Reduce output size as you go deeper into the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Performance Bottlenecks\n",
    "- **CNNs**: First fully connected layer after convolution blocks often contains most parameters\n",
    "- **Memory**: Large dense layers can cause out-of-memory errors\n",
    "- **Example**: 8×8×256 input to 1024-node dense layer = 16.7M parameters\n",
    "- **Solution**: Use global average pooling instead of flattening for large spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Flatten vs Global Average Pooling\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_shape = (8, 8, 256)\n",
    "\n",
    "# Method 1: Flatten (many parameters)\n",
    "model_flatten = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu')\n",
    "])\n",
    "\n",
    "# Method 2: Global Average Pooling (few parameters)\n",
    "model_gap = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu')\n",
    "])\n",
    "\n",
    "print(\"Flatten method:\")\n",
    "model_flatten.summary()\n",
    "\n",
    "print(\"\\nGlobal Average Pooling method:\")\n",
    "model_gap.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Autoencoder Implementation\n",
    "Implement an autoencoder with architecture: 512 → 32 → 16 → 512 using sigmoid activation for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "def create_autoencoder():\n",
    "    autoencoder = models.Sequential([\n",
    "        layers.Dense(32, activation='sigmoid', input_shape=(512,)),\n",
    "        layers.Dense(16, activation='sigmoid'),\n",
    "        layers.Dense(32, activation='sigmoid'),\n",
    "        layers.Dense(512, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    autoencoder.compile(loss='mse', optimizer='adam')\n",
    "    return autoencoder\n",
    "\n",
    "exercise_autoencoder = create_autoencoder()\n",
    "exercise_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: CNN Output Size Calculation\n",
    "Calculate the final output size for the given CNN architecture (ignoring batch dimension):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "def calculate_cnn_output():\n",
    "    input_size = 64\n",
    "    \n",
    "    # Layer 1: Conv2D with valid padding\n",
    "    size_after_conv1 = (input_size - 5) // 1 + 1  # 60\n",
    "    \n",
    "    # Layer 2: MaxPool with same padding\n",
    "    size_after_pool1 = (size_after_conv1 + 2 - 1) // 2  # 30\n",
    "    \n",
    "    # Layer 3: Conv2D with same padding\n",
    "    size_after_conv2 = (size_after_pool1 + 1 - 1) // 1  # 30\n",
    "    \n",
    "    # Layer 4: MaxPool with same padding\n",
    "    size_after_pool2 = (size_after_conv2 + 2 - 1) // 2  # 15\n",
    "    \n",
    "    # Layer 5: Conv2D with same padding and stride 2\n",
    "    size_after_conv3 = (size_after_pool2 + 2 - 1) // 2  # 8\n",
    "    \n",
    "    return size_after_conv3\n",
    "\n",
    "final_size = calculate_cnn_output()\n",
    "print(f\"Final output size: {final_size}×{final_size}\")\n",
    "print(f\"With 32 filters, final output shape would be: (None, {final_size}, {final_size}, 32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Data Pipeline Implementation\n",
    "Create a data pipeline for the CO2 dataset that prepares sequences of 12 months for RNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solution\n",
    "def create_co2_pipeline(data, sequence_length=12, batch_size=32):\n",
    "    \"\"\"Create a tf.data pipeline for CO2 sequences\"\"\"\n",
    "    \n",
    "    # Normalize the data\n",
    "    co2_values = data['Average'].values\n",
    "    co2_mean = co2_values.mean()\n",
    "    co2_std = co2_values.std()\n",
    "    normalized_co2 = (co2_values - co2_mean) / co2_std\n",
    "    \n",
    "    # Create sequences\n",
    "    sequences, targets = create_sequences(normalized_co2, sequence_length)\n",
    "    \n",
    "    # Create tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, targets))\n",
    "    dataset = dataset.shuffle(1000).batch(batch_size)\n",
    "    \n",
    "    return dataset, co2_mean, co2_std\n",
    "\n",
    "# Test the pipeline\n",
    "co2_dataset, mean, std = create_co2_pipeline(co2_data)\n",
    "\n",
    "print(\"CO2 Data Pipeline created successfully!\")\n",
    "print(f\"Normalization - Mean: {mean:.2f}, Std: {std:.2f}\")\n",
    "\n",
    "for seq_batch, target_batch in co2_dataset.take(1):\n",
    "    print(f\"Sequence batch shape: {seq_batch.shape}\")\n",
    "    print(f\"Target batch shape: {target_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Summary\n",
    "\n",
    "This chapter provided hands-on experience with three fundamental deep learning architectures:\n",
    "\n",
    "1. **Fully Connected Networks (Autoencoders)**: \n",
    "   - Unsupervised learning for image reconstruction\n",
    "   - Compression and reconstruction phases\n",
    "   - Applications in denoising and feature learning\n",
    "   - MNIST dataset: 70,000 28×28 handwritten digit images\n",
    "\n",
    "2. **Convolutional Neural Networks**:\n",
    "   - Specialized for spatial data like images\n",
    "   - Hierarchical feature learning through convolution and pooling\n",
    "   - Parameter efficiency through weight sharing\n",
    "   - CIFAR-10 dataset: 60,000 32×32 color images across 10 classes\n",
    "   - Achieved ~72% training accuracy\n",
    "\n",
    "3. **Recurrent Neural Networks**:\n",
    "   - Designed for sequential and time-series data\n",
    "   - Maintain memory through hidden states\n",
    "   - Applications in forecasting and temporal pattern recognition\n",
    "   - CO2 concentration prediction using historical data\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Each network type has distinct strengths for different data types\n",
    "- Proper parameter selection is crucial to avoid errors\n",
    "- Understanding these fundamentals enables exploration of advanced architectures\n",
    "- Real-world applications demonstrate practical utility of each approach\n",
    "\n",
    "**Next Steps**:\n",
    "- Explore advanced architectures (ResNet, LSTM, Transformers)\n",
    "- Learn about regularization techniques to prevent overfitting\n",
    "- Study transfer learning and fine-tuning pre-trained models\n",
    "- Experiment with different optimization strategies and loss functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
